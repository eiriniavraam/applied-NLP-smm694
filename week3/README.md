# Week 3 ― READMEs

- [Week 3 ― READMEs](#week-3--readmes)
  - [Overview](#overview)
  - [Materials](#materials)

## Overview

In week 3, we'll pursue there learning goals:

- Appreciating the anatomy of word2vec
- Assigning a role to new forms of embeddings
- Understanding the various steps to train ad hoc embeddings 

| Week (date)   | Agenda                                                    |
| ------------- | --------------------------------------------------------- |
| **3 (03-06)** | **Vector semantics and embeddings**                       |
|               | ― word2vec                                                |
|               | ― visualizing embeddings                                  |
|               | ― semantic properties of embeddings                       |
|               | ― bias and embeddings                                     |
|               | ― evaluating vector models                                |
|               | ― doc2vec                                                 |
|               | **Webinar**                                               |
|               | ― Q&A session                                             |
|               | ― problem set discussion                                  |
|               | ― training word embeddings (Gensim)                       |
|               | ― training document embeddings (Gensim)                   |
|               | ― passing embeddings through ML pipelines (scikit-learn)  |
|               | ― network analysis of embeddings (NetworkX)               |

## Materials

Below are the materials at the center of week 3:

- readings: 
  - lecture notes: `ln_3_*.ipynb`
  - journal articles:
      - [Efficient estimation of word representations in vector space](https://arxiv.org/pdf/1301.3781.pdf%C3%AC%E2%80%94%20%C3%AC%E2%80%9E%C5%93)
      - [Distributed representations of words and phrases and their compositionality](http://www.cs.columbia.edu/~blei/seminar/2016_discrete_data/readings/MikolovSutskeverChenCorradoDean2013.pdf)