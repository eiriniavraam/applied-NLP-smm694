{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Session 2, part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Representing words and meanings\n",
    "- Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/_99.jpg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to represent the meaning of a word?\n",
    "=====================================\n",
    "\n",
    "A machine's perspective\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Human beings are entrenched in the symbols and social categories of natural language, while machines are not. Hence, machines are not able to associate meanings with lexemes.\n",
    "\n",
    "This explains why analyzing massive datasets of natural language has been traditionally taxing/impossible. In fact, human beings are really good at making sense of language but they are bad at computing (so, hand-curated work-flows are not scalable). On the contrary, machines are really good at computing but they're just dull (so, computation capacity looks for a work-flow to scale-up)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mainly, there are two strategies through which machines can handle meanings:\n",
    "\n",
    "+ human beings can provide machines with 'pattern-matching' rules that induce meaningful responses vis a' vis natural language inputs\n",
    "+ with the aid of statistical frameworks (e.g. Distributional Representations), machines can discover/learn the  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pattern-matching route\n",
    "===================\n",
    "\n",
    "Two prominent natural language tools tools that draw on pattern matching:\n",
    "\n",
    "+ regular expressions\n",
    "+ WordNet (an example of annotated dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Regular expressions\n",
    "================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Regular expressions use a special kind (class) of formal language grammar called a regular grammar.\n",
    "\n",
    "Regular grammars have predictable, provable behavior, and yet are flexible enough to power some of the most sophisticated dialog engines and chatbots on the market. Amazon Alexa and Google Now are mostly pattern-based engines that rely on regular grammars.\n",
    "\n",
    "Deep, complex regular grammar rules can often be expressed in a single line of code called a regular expression. There are successful chatbot frameworks in Python, like Will, that rely exclusively on this kind of language to produce some useful and interesting behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/_9.png\" width=\"100%\">\n",
    "\n",
    "Examples of home assistant products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Regular expressions: A minimal chatbot (1/3)\n",
    "================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "m0 : <re.Match object; span=(0, 10), match='Hello Rosa'>\n",
      "\n",
      "m1 : <re.Match object; span=(0, 5), match='hi ho'>\n",
      "\n",
      "m2 : <re.Match object; span=(0, 3), match='hey'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Credits to Lane, Howard & Hapke (2019)\n",
    "'''\n",
    "\n",
    "# load re module\n",
    "import re\n",
    "\n",
    "# greeting matcher\n",
    "r = \"(hi|hello|hey)[ ]*([a-z]*)\"\n",
    "\n",
    "# matcher in action\n",
    "m0 = re.match(r, 'Hello Rosa', flags=re.IGNORECASE)\n",
    "m1 = re.match(r, \"hi ho, hi ho, it's off to work ...\", flags=re.IGNORECASE)\n",
    "m2 = re.match(r, \"hey, what's up\", flags=re.IGNORECASE)\n",
    "\n",
    "print(\"\"\"\n",
    "m0 : {}\n",
    "\n",
    "m1 : {}\n",
    "\n",
    "m2 : {}\n",
    "\"\"\".format(m0, m1, m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Regular expressions: A minimal chatbot (2/3)\n",
    "================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 7), match='yo Rosa'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's expand the greeting matcher\n",
    "r = r\"[^a-z]*([y]o|[h']?ello|ok|hey|(good[ ])?(morn[gin']{0,3}|\"\\\n",
    "    r\"afternoon|even[gin']{0,3}))[\\s,;:]{1,3}([a-z]{1,20})\"\n",
    "\n",
    "# ... and ignore the case of text\n",
    "re_greeting = re.compile(r, flags=re.IGNORECASE)\n",
    "\n",
    "# matcher in action (uncomment the below to run)\n",
    "re_greeting.match('Hello Rosa')\n",
    "re_greeting.match('Hello Rosa').groups()\n",
    "re_greeting.match(\"Good morning Rosa\")\n",
    "re_greeting.match(\"Good Manning Rosa\")\n",
    "re_greeting.match('Good evening Rosa Parks').groups() \n",
    "re_greeting.match(\"Good Morn'n Rosa\")\n",
    "re_greeting.match(\"yo Rosa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Regular expressions: A minimal chatbot (3/3)\n",
    "================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello bot\n",
      "Hi Simone, How are you?\n"
     ]
    }
   ],
   "source": [
    "# set of name for the bot\n",
    "my_names = set(['rosa', 'rose', 'chatty', 'chatbot', 'bot', 'chatterbot'])\n",
    "\n",
    "# possible curt names to use in the conversation\n",
    "curt_names = set(['hal', 'you', 'u'])\n",
    "\n",
    "# name of the conversant (we pretend to know her/him)\n",
    "greeter_name = 'Simone'\n",
    "\n",
    "# let's recycle the matcher\n",
    "match = re_greeting.match(input())\n",
    "\n",
    "# conditional statment that initiates the conversation (run and populate)\n",
    "if match:\n",
    "    at_name = match.groups()[-1]\n",
    "    if at_name in curt_names:\n",
    "        print(\"Good one.\")\n",
    "    elif at_name.lower() in my_names:\n",
    "        print(\"Hi {}, How are you?\".format(greeter_name))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
