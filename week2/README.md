# Week 2 － Representing words and meanings

- [Week 2 － Representing words and meanings](#week-2--representing-words-and-meanings)
  - [Overview](#overview)
  - [Materials](#materials)

## Overview

In Week 2, we'll pursue three goals:

- Familiarizing with the field of computational linguistics, which shows 
  a distinctive interest in the representation of meanings
- Appreciating alternative approaches to the representation of meanings
- Understanding how word embeddings tackle the longstanding challenges in 
  the representation of meanings 

| **2 (27-05)** | **Representing words and meanings**               |
| ------------- | ------------------------------------------------- |
|               | ― words and meanings in linguistics               |
|               | ― words and meanings in machines                  |
|               | ― from WordNet to word2vec (via word vectors)     |
|               | **Webinar**                                       |
|               | ― Q&A session                                     |
|               | ― problem set discussion                          |
|               | ― using WordNet with NLTK                         |
|               | ― loading a pre-trained model of language (spaCy) |
|               | ― processing text through NLP pipelines (spaCy)   |
|               | ― leveraging word vectors (NumPy)                 |

## Materials

Below are the materials at the center of week 2:

- readings: 
  - lecture notes: `ln_2_*.ipynb`
  - textbook: sections 6.1 - 6.7 (included) included in Jurafksi and Martin's book,
    [chapter 6](https://web.stanford.edu/~jurafsky/slp3/6.pdf). 