{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 5, part III\n",
    "\n",
    "# ―Sentiment, affect, and connotation\n",
    "\n",
    "<img src=\"images/_1.jpeg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bayesian inference\n",
    "\n",
    "The final equation for the class chosen by a NBC is thus:\n",
    "\n",
    "\\begin{equation}\n",
    "c_{NB} = argmaxP(c) \\Pi P(f|c)\n",
    "\\end{equation}\n",
    "\n",
    "with $c \\in C$ and $f \\in F$\n",
    "\n",
    "As Jurafsky and Martin (2019) note, Naive Bayes calculations, like calculations for \n",
    "language modeling, are done in log space, to avoid underflow and increase speed. Hence,\n",
    "Eq. [6] can dispensed as follows [7]:\n",
    "\n",
    "\\begin{equation}\n",
    "c_{NB} = argmax log P(c) + \\sum log P(w_{i}|c)\n",
    "\\end{equation}\n",
    "\n",
    "with $c \\in C$ and $i \\in V$, where $V$ is the dictionary of the corpus of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training the NBC ― prior probabilities\n",
    "\n",
    "For the document prior $P(c)$ we ask what percentage of the documents in our training \n",
    "set are in each class c.\n",
    "\n",
    "Let Nc be the number of documents in our training data with class $c$ and $N_{doc}$ be \n",
    "the total number of documents:\n",
    "\n",
    "$\\hat P(c) = \\frac{N_{c}}{N_{doc}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training the NBC ― conditional distributions of features\n",
    "\n",
    "To learn the probability $P(f_{i}|c)$, we'll assume a feature is just the existence of a \n",
    "word in the document's bag of words (Jurafsky & Martin, 2019).\n",
    "\n",
    "$P(w_{i}|c)$ is the fraction of times the word $w_{i}$ appears among all wods in all \n",
    "documents of class $c$:\n",
    "+ we first concatenate all documents with class $c$\n",
    "+ then, we use the frequency of $w_{i}$ in this concatenated document to give a maximum\n",
    "  likelihood estimate of the probability:\n",
    "  \n",
    "  $\\hat P(w_{i}|c) = \\frac{|w_{i}, c|}{\\sum_{w \\in V} |w, c|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training the NBC ― caveats\n",
    "\n",
    "**Problem:** since NBC multiplies all the features likelihood $(w_{i}|c)$, \n",
    "zero-probabilites in any  word included in a test set document will cause the \n",
    "probability of the class to be zero!\n",
    "\n",
    "Non mutually exclusive **solutions**:\n",
    "\n",
    "+ add-one (Laplace) smoothing\n",
    "+ torough NLP pipeline dealing with rare or oov words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example\n",
    "\n",
    "+ Setup:\n",
    "  * sentiment analysis domain with the two classes:\n",
    "    - positive (+) and \n",
    "    - negative (-)\n",
    "+ Data:\n",
    "  * training and test documents simplified from actual movie reviews\n",
    "  \n",
    "| Set      | Class | Documents                             |\n",
    "|----------|-------|---------------------------------------|\n",
    "| Training | -     | just plain boring                     |\n",
    "|          | -     | entirely predictable and lacks energy | \n",
    "|          | -     | no surprise and very few laughs       |\n",
    "|          | +     | very powerful                         |\n",
    "|          | +     | the most fun film of the summer       |\n",
    "| Test     | ?     | predictable with no fun               |\n",
    "\n",
    "Source is Jurafsky and Martin (2019, page: 62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example: computing priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Set      | Class | Documents                             |\n",
    "|----------|-------|---------------------------------------|\n",
    "| Training | -     | just plain boring                     |\n",
    "|          | -     | entirely predictable and lacks energy | \n",
    "|          | -     | no surprise and very few laughs       |\n",
    "|          | +     | very powerful                         |\n",
    "|          | +     | the most fun film of the summer       |\n",
    "| Test     | ?     | predictable with no fun               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$P(-) = \\frac{3}{5}$\n",
    "\n",
    "$P(+) = \\frac{2}{5}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example: computing word likelihood\n",
    "\n",
    "Design:\n",
    "\n",
    "+ oov words are filtered out\n",
    "  * we don't consider 'with'\n",
    "+ we use 'add-one' smoothing\n",
    "  * $\\hat P(w_{i}|c) = \\frac{|w_{i}, c|}{\\sum_{w \\in V} |w, c| + 1}$\n",
    "\n",
    "| Word        | $c = -$              | $c = +$            |\n",
    "| ----------- | -------------------- | -------------------|\n",
    "| predictable |  (1 + 1) / (14 + 20) | (0 + 1) / (9 + 20) |\n",
    "| no          |  (1 + 1) / (14 + 20) | (0 + 1) / (9 + 20) |\n",
    "| fun         |  (0 + 1) / (14 + 20) | (1 + 1) / (9 + 20) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example: estimating doc-to-class affiliations \n",
    "\n",
    "$P(-)P(s|-) = \\frac{3}{5} \\times \\frac{2 \\times 2 \\times 1}{34^{3}} = \n",
    "6.1 \\times 10^{-5}$\n",
    "\n",
    "$P(+)P(s|+) = \\frac{2}{5} \\times \\frac{1 \\times 1 \\times 2}{29^{3}} = \n",
    "3.2 \\times 10^{-5}$\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
